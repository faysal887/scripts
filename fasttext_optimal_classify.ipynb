{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to prevent to restart kernel when any changes are made to any imported file\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# to import any file from some other directory\n",
    "\n",
    "# to stop printing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# to increase cells width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# to enable collapsible Headings and Functions\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user\n",
    "# !jupyter nbextensions_configurator enable --user\n",
    "# !jupyter nbextension enable codefolding/main\n",
    "# search collapsible to enable\n",
    "\n",
    "# enable dark theme\n",
    "# !pip install jupyterthemes\n",
    "# !jt -t monokai\n",
    "\n",
    "# monokai\n",
    "# solarizedd\n",
    "# !jt -r\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import json\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "import os.path, time\n",
    "from datetime import datetime, timedelta\n",
    "from threading import Timer\n",
    "import pdb, random\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import fasttext\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloud_user/faisal/experiments/100_day_ml\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "PATH=\"/home/cloud_user/faisal/experiments/real_not_real_kaggle/data1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(f\"{PATH}train.csv\")\n",
    "test=pd.read_csv(f\"{PATH}test.csv\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=train.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0  1   NaN     NaN       \n",
       "\n",
       "                                                                    text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "\n",
       "   target  \n",
       "0  1       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(mydf, Xcol, ycol):\n",
    "    mydf[Xcol] = mydf[Xcol].apply(lambda x: ((x.encode(\"unicode_escape\").decode(\"utf-8\"))))\n",
    "    mydf[Xcol] = mydf[Xcol].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n",
    "    mydf[Xcol] = mydf[Xcol].str.lower().str.replace('\\n',' ')\n",
    "    mydf[ycol] = mydf[ycol].astype(str)\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(df, fname, col):\n",
    "    f = open(fname,'w')\n",
    "          \n",
    "    f.write('\\n'.join(df[col].tolist()))\n",
    "    f.close()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_fasttext_syntax(mydf, Xcol, ycol, fasttext_txt):\n",
    "    mydf[fasttext_txt] = '__label__'+mydf[ycol]+' '+mydf[Xcol]\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random(mydf, Xcol, ycol, fasttext_txt):\n",
    "    df=preprocess(mydf, Xcol, ycol)\n",
    "    trn_df, vld_df, ts_df = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "    trn_df, vld_df=to_fasttext_syntax(trn_df, Xcol, ycol, fasttext_txt), to_fasttext_syntax(vld_df, Xcol, ycol, fasttext_txt)\n",
    "    print(\"Train: \", trn_df.shape); print(\"Valid: \", vld_df.shape); print(\"Test: \", ts_df.shape)\n",
    "    return trn_df, vld_df, ts_df\n",
    "\n",
    "\n",
    "def split_dt(mydf, Xcol, ycol, fasttext_txt, trn_split, vld_split):\n",
    "    df=preprocess(mydf, Xcol, ycol)\n",
    "    trn_df = df.loc[df.data<=trn_split]\n",
    "    vld_df = df.loc[df.data<=vld_split]\n",
    "    ts_df  = df.loc[df.data>vld_split]\n",
    "    trn_df, vld_df=to_fasttext_syntax(mydf, Xcol, ycol, fasttext_txt), to_fasttext_syntax(mydf, Xcol, ycol, fasttext_txt)\n",
    "    print(\"Train: \", trn_df.shape); print(\"Valid: \", vld_df.shape); print(\"Test: \", ts_df.shape)\n",
    "    return trn_df, vld_df, ts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (4567, 6)\n",
      "Valid:  (1523, 6)\n",
      "Test:  (1523, 5)\n"
     ]
    }
   ],
   "source": [
    "Xcol=\"text\"\n",
    "ycol=\"target\"\n",
    "fasttext_txt=\"ft_txt\"\n",
    "\n",
    "# random split\n",
    "trn_df, vld_df, ts_df=split_random(df, Xcol, ycol, fasttext_txt)\n",
    "\n",
    "# split on date\n",
    "# trn_split=\"2019-08-31\";vld_split=\"2019-10-31\"\n",
    "# trn_df, vld_df, ts_df=split_dt(mydf, Xcol, ycol, fasttext_txt, trn_split, vld_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(test_df, classifier, Xcol, ycol):\n",
    "    y_pred=[]\n",
    "    y_true=[]\n",
    "    for txt, lbl in zip(test_df[Xcol], test_df[ycol]):\n",
    "        y_pred.append(classifier.predict([txt])[0][0][0][9:])\n",
    "        y_true.append(lbl)\n",
    "\n",
    "    y_pred = np.array(y_pred, dtype='O')\n",
    "    y_true = np.array(y_true, dtype='O')\n",
    "    conf_mat=confusion_matrix(y_true, y_pred)\n",
    "    cls_rpt=classification_report(y_true, y_pred)\n",
    "    print(conf_mat)\n",
    "    print(cls_rpt)\n",
    "    print(f\"\\n =================== \\n\")\n",
    "    return conf_mat, cls_rpt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_fasttext(trn_df, vld_df, ts_df, fasttext_txt, autotune_label):\n",
    "    results=[]\n",
    "    \n",
    "    trn_fn, vld_fn = \"df.train\", \"df.valid\"\n",
    "    \n",
    "    _, _=save_file(trn_df, trn_fn, fasttext_txt), save_file(vld_df, vld_fn, fasttext_txt)\n",
    "    \n",
    "    classifier1 = fasttext.train_supervised(trn_fn, loss='softmax')\n",
    "    print(\"\\nclassifier1: \")\n",
    "    conf_mat1, cls_rpt1 = get_results(ts_df, classifier1, Xcol, ycol)\n",
    "    results.append((conf_mat1, cls_rpt1))\n",
    "    \n",
    "    classifier2 = fasttext.train_supervised(input=trn_fn, autotuneValidationFile=vld_fn, autotuneMetric=f\"f1:__label__{autotune_label}\")\n",
    "    print(\"classifier2: \")\n",
    "    conf_mat2, cls_rpt2 = get_results(ts_df, classifier2, Xcol, ycol)\n",
    "    results.append((conf_mat2, cls_rpt2))\n",
    "\n",
    "    classifier3 = fasttext.train_supervised(input=trn_fn, autotuneValidationFile=vld_fn, autotuneDuration=60)\n",
    "    print(\"classifier3: \")\n",
    "    conf_mat3, cls_rpt3 = get_results(ts_df, classifier3, Xcol, ycol)\n",
    "    results.append((conf_mat3, cls_rpt3))\n",
    "\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classifier1: \n",
      "[[745 114]\n",
      " [195 469]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       859\n",
      "           1       0.80      0.71      0.75       664\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1523\n",
      "   macro avg       0.80      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n",
      "\n",
      " =================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = classify_fasttext(trn_df, vld_df, ts_df, fasttext_txt, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
